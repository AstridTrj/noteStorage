{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import lightgbm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_path = \"D:/PythonProject/didi_giscup/data/giscup_2021/processed_train/\"\n",
    "test_path = \"D:/PythonProject/didi_giscup/data/giscup_2021/20200901/\"\n",
    "result_path = \"D:/PythonProject/didi_giscup/result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_list = list(pd.read_csv(trian_path + \"20200801/feature.csv\").columns)\n",
    "\n",
    "train_data = pd.DataFrame(columns=fe_list)\n",
    "test_data = pd.read_csv(test_path + \"feature.csv\").drop([\"ata\"], axis=1)\n",
    "\n",
    "def read_data(start: int, end: int):\n",
    "    day_list = list(range(start, end + 1))\n",
    "    if 803 in day_list:\n",
    "        day_list.remove(803)\n",
    "    print(\"day list: \", day_list)\n",
    "        \n",
    "    global train_data, test_data\n",
    "    for d in day_list:\n",
    "        path = trian_path + \"20200\" + str(d) + \"/\"\n",
    "        temp_df = pd.read_csv(path + \"feature.csv\")\n",
    "        train_data = pd.concat([train_data, temp_df])\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    print(\"train shape: \", train_data.shape)\n",
    "    print(\"test shape: \", test_data.shape)\n",
    "\n",
    "\n",
    "def mape_score(pred: list, true: list):\n",
    "    n = len(pred)\n",
    "    pred_true = pd.DataFrame({\"pred\": pred, \"true\": true})\n",
    "    pred_true[\"pred\"] = np.abs(pred_true[\"pred\"] - pred_true[\"true\"]) / pred_true[\"true\"]\n",
    "    return pred_true[\"pred\"].sum() / n\n",
    "\n",
    "\n",
    "def trian_model_cross_lgb():\n",
    "    global train_data, test_data\n",
    "    label = train_data[\"ata\"]\n",
    "    \n",
    "    feature = list(train_data.columns)\n",
    "    print(\"columns len: \", len(train_data.columns))\n",
    "    print(\"columns: \", train_data.columns)\n",
    "    feature.remove(\"order_id\")\n",
    "    feature.remove(\"ata\")\n",
    "    for fe in feature:\n",
    "        train_data[fe] = train_data[fe].astype(np.float)\n",
    "    \n",
    "    # label_encode = LabelEncoder()\n",
    "    # label_encode.fit(train_data[\"driver_id\"])\n",
    "    # test_data[\"driver_id\"] = test_data[\"driver_id\"].map(lambda x: -1 if x not in label_encode.classes_ else x)\n",
    "    # label_encode.classes_ = np.append(label_encode.classes_, -1)\n",
    "    # train_data[\"driver_id\"] = label_encode.transform(train_data[\"driver_id\"])\n",
    "    # test_data[\"driver_id\"] = label_encode.transform(test_data[\"driver_id\"])\n",
    "    \n",
    "    train_df = train_data[feature]\n",
    "    test_df = test_data[feature]\n",
    "    \n",
    "    # cross validation\n",
    "    preds = np.zeros(train_df.shape[0])\n",
    "    test_pred = np.zeros(test_df.shape[0])\n",
    "    model = lightgbm.LGBMRegressor(n_estimators=10000, metric='mape')\n",
    "    kf = KFold(n_splits=5, random_state=418, shuffle=True)\n",
    "    for k, (train_id, valid_id) in enumerate(kf.split(train_df, label)):\n",
    "        \n",
    "        train_x = train_df.iloc[train_id]\n",
    "        valid_x = train_df.iloc[valid_id]\n",
    "        train_y = label.iloc[train_id]\n",
    "        valid_y = label.iloc[valid_id]\n",
    "        \n",
    "        model.fit(train_x, train_y, eval_set=(valid_x, valid_y), early_stopping_rounds=100, verbose=100)\n",
    "        preds[valid_id] = model.predict(valid_x, num_iteration=model.best_iteration_)\n",
    "        test_pred += model.predict(test_df, num_iteration=model.best_iteration_)\n",
    "    score = mape_score(preds, label)\n",
    "    print(\"mape score by five: \", score)\n",
    "    test_data[\"result\"] = test_pred / 5\n",
    "    test_data = test_data.rename(columns={\"order_id\": \"id\"})\n",
    "    \n",
    "    t = datetime.datetime.now()\n",
    "    t_str = str(t.month) + str(t.day) + \"_\" + str(t.hour) + \"-\" + str(t.minute) + \"-\" + str(t.second)\n",
    "#     test_data[[\"id\", \"result\"]].to_csv(result_path + \"submission\" + t_str + \".csv\", index=False)\n",
    "\n",
    "\n",
    "def train_model_one_lgb():\n",
    "    global train_data, test_data\n",
    "    label = train_data[\"ata\"]\n",
    "    \n",
    "    feature = list(train_data.columns)\n",
    "    print(\"columns len: \", len(train_data.columns))\n",
    "    print(\"columns: \", train_data.columns)\n",
    "    feature.remove(\"order_id\")\n",
    "    feature.remove(\"ata\")\n",
    "    for fe in feature:\n",
    "        train_data[fe] = train_data[fe].astype(np.float)\n",
    "    \n",
    "    train_df = train_data[feature]\n",
    "    test_df = test_data[feature]\n",
    "    model = lightgbm.LGBMRegressor(n_estimators=10000, metric='mape',)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(train_df, label, random_state=1021, test_size=0.2, shuffle=False)\n",
    "    model.fit(train_x, train_y, eval_set=(test_x, test_y), early_stopping_rounds=100, verbose=100)\n",
    "    pred_y = model.predict(test_x, num_iteration=model.best_iteration_)\n",
    "    score = mape_score(pred_y, test_y)\n",
    "    print(\"mape score by one: \", score)\n",
    "    test_data[\"result\"] = model.predict(test_df, num_iteration=model.best_iteration_)\n",
    "    test_data = test_data.rename(columns={\"order_id\": \"id\"})\n",
    "    \n",
    "    t = datetime.datetime.now()\n",
    "    t_str = str(t.month) + str(t.day) + \"_\" + str(t.hour) + \"-\" + str(t.minute) + \"-\" + str(t.second)\n",
    "    test_data[[\"id\", \"result\"]].to_csv(result_path + \"submission\" + t_str + \".csv\", index=False)\n",
    "\n",
    "\n",
    "def train_model_ctb():\n",
    "    global train_data, test_data\n",
    "    label = train_data[\"ata\"]\n",
    "    \n",
    "    feature = list(train_data.columns)\n",
    "    print(\"columns len: \", len(train_data.columns))\n",
    "    print(\"columns: \", train_data.columns)\n",
    "    feature.remove(\"order_id\")\n",
    "    feature.remove(\"ata\")\n",
    "    for fe in feature:\n",
    "        train_data[fe] = train_data[fe].astype(np.float)\n",
    "    \n",
    "    train_df = train_data[feature]\n",
    "    test_df = test_data[feature]\n",
    "    model = lightgbm.LGBMRegressor(n_estimators=10000, metric='mae', learning_rate=0.5)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(train_df, label, random_state=1021, test_size=0.2, shuffle=False)\n",
    "    model.fit(train_x, train_y, eval_set=(test_x, test_y), early_stopping_rounds=100, verbose=100)\n",
    "    pred_y = model.predict(test_x, num_iteration=model.best_iteration_)\n",
    "    score = mape_score(pred_y, test_y)\n",
    "    print(\"mape score by one: \", score)\n",
    "    test_data[\"result\"] = model.predict(test_df, num_iteration=model.best_iteration_)\n",
    "    test_data = test_data.rename(columns={\"order_id\": \"id\"})\n",
    "    \n",
    "    t = datetime.datetime.now()\n",
    "    t_str = str(t.month) + str(t.day) + \"_\" + str(t.hour) + \"-\" + str(t.minute) + \"-\" + str(t.second)\n",
    "    test_data[[\"id\", \"result\"]].to_csv(result_path + \"submission\" + t_str + \".csv\", index=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    read_data(801, 804)\n",
    "    \n",
    "    trian_model_cross_lgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day list:  [801, 802, 804]\n",
      "train shape:  (320618, 37)\n",
      "test shape:  (288076, 36)\n",
      "columns len:  37\n",
      "columns:  Index(['order_id', 'ata', 'distance', 'simple_eta', 'driver_id', 'slice_id',\n",
      "       'weather', 'hightemp', 'lowtemp', 'temp_sub', 'slice_1m', 'slice_30m',\n",
      "       'slice_1h', 'link_cnt', 'mean_distance', 'speed_one', 'link_time_sum',\n",
      "       'link_time_mean', 'link_time_max', 'link_time_min', 'speed_two',\n",
      "       'link_cur_sta_mean', 'link_cur_sta_sum', 'conges_cnt', 'conges_sum',\n",
      "       'amble_cnt', 'amble_sum', 'cross_cnt', 'cross_time_sum',\n",
      "       'cross_time_mean', 'cross_time_max', 'cross_time_mode', 'cross_from',\n",
      "       'cross_to', 'cross_from_last', 'cross_to_last', 'link_time_sum_ratio'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's mape: 0.151706\n",
      "[200]\tvalid_0's mape: 0.150825\n",
      "[300]\tvalid_0's mape: 0.150442\n",
      "[400]\tvalid_0's mape: 0.150245\n",
      "[500]\tvalid_0's mape: 0.150087\n",
      "[600]\tvalid_0's mape: 0.149938\n",
      "[700]\tvalid_0's mape: 0.149871\n",
      "[800]\tvalid_0's mape: 0.149765\n",
      "[900]\tvalid_0's mape: 0.149667\n",
      "[1000]\tvalid_0's mape: 0.149564\n",
      "[1100]\tvalid_0's mape: 0.149555\n",
      "Early stopping, best iteration is:\n",
      "[1027]\tvalid_0's mape: 0.149529\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's mape: 0.152207\n",
      "[200]\tvalid_0's mape: 0.151259\n",
      "[300]\tvalid_0's mape: 0.150949\n",
      "[400]\tvalid_0's mape: 0.150624\n",
      "[500]\tvalid_0's mape: 0.150415\n",
      "[600]\tvalid_0's mape: 0.150266\n",
      "[700]\tvalid_0's mape: 0.150159\n",
      "[800]\tvalid_0's mape: 0.150061\n",
      "[900]\tvalid_0's mape: 0.150018\n",
      "[1000]\tvalid_0's mape: 0.150002\n",
      "Early stopping, best iteration is:\n",
      "[923]\tvalid_0's mape: 0.149983\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's mape: 0.15196\n",
      "[200]\tvalid_0's mape: 0.151125\n",
      "[300]\tvalid_0's mape: 0.150786\n",
      "[400]\tvalid_0's mape: 0.150526\n",
      "[500]\tvalid_0's mape: 0.150261\n",
      "[600]\tvalid_0's mape: 0.150101\n",
      "[700]\tvalid_0's mape: 0.150004\n",
      "[800]\tvalid_0's mape: 0.149927\n",
      "[900]\tvalid_0's mape: 0.149765\n",
      "[1000]\tvalid_0's mape: 0.149717\n",
      "[1100]\tvalid_0's mape: 0.149718\n",
      "[1200]\tvalid_0's mape: 0.149653\n",
      "[1300]\tvalid_0's mape: 0.149606\n",
      "Early stopping, best iteration is:\n",
      "[1259]\tvalid_0's mape: 0.149597\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's mape: 0.151339\n",
      "[200]\tvalid_0's mape: 0.15059\n",
      "[300]\tvalid_0's mape: 0.150165\n",
      "[400]\tvalid_0's mape: 0.149984\n",
      "[500]\tvalid_0's mape: 0.149801\n",
      "[600]\tvalid_0's mape: 0.149649\n",
      "[700]\tvalid_0's mape: 0.149533\n",
      "[800]\tvalid_0's mape: 0.149437\n",
      "[900]\tvalid_0's mape: 0.149384\n",
      "[1000]\tvalid_0's mape: 0.149311\n",
      "[1100]\tvalid_0's mape: 0.149267\n",
      "Early stopping, best iteration is:\n",
      "[1082]\tvalid_0's mape: 0.149253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's mape: 0.15293\n",
      "[200]\tvalid_0's mape: 0.151956\n",
      "[300]\tvalid_0's mape: 0.151593\n",
      "[400]\tvalid_0's mape: 0.151274\n",
      "[500]\tvalid_0's mape: 0.151064\n",
      "[600]\tvalid_0's mape: 0.150875\n",
      "[700]\tvalid_0's mape: 0.150776\n",
      "[800]\tvalid_0's mape: 0.15067\n",
      "[900]\tvalid_0's mape: 0.150643\n",
      "[1000]\tvalid_0's mape: 0.150575\n",
      "[1100]\tvalid_0's mape: 0.150489\n",
      "[1200]\tvalid_0's mape: 0.150429\n",
      "[1300]\tvalid_0's mape: 0.150428\n",
      "[1400]\tvalid_0's mape: 0.150413\n",
      "[1500]\tvalid_0's mape: 0.150359\n",
      "[1600]\tvalid_0's mape: 0.150347\n",
      "[1700]\tvalid_0's mape: 0.150297\n",
      "[1800]\tvalid_0's mape: 0.150303\n",
      "Early stopping, best iteration is:\n",
      "[1700]\tvalid_0's mape: 0.150297\n",
      "mape score by five:  0.14973174142905518\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# five mape score three datys: 0.14973174142905518\n",
    "# five mape score all days: 0.14015414626974915 --- 0.14508\n",
    "# one mape score all dats: 0.13986354280512076  --- 0.14572\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
